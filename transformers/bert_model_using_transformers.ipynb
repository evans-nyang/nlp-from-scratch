{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKDbLKpYNvAk"
   },
   "source": [
    "# Guide to use BERT model using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZnYzyjoSH0F"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dri6P8bCt7Di",
    "outputId": "88f73604-0b74-4706-b177-a74d9e700069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/teng/development/mlenv/lib/python3.10/site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/teng/development/mlenv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/teng/development/mlenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/teng/development/mlenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/teng/development/mlenv/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/teng/development/mlenv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/teng/development/mlenv/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/teng/development/mlenv/lib/python3.10/site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L71c4v7KSMui"
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CwpCpxYxJ_CE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 21:42:24.092996: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-28 21:42:24.109557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738089744.127763  263702 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738089744.133187  263702 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-28 21:42:24.168217: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VGwdmELJNtTQ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xD3otTdScNd"
   },
   "source": [
    "## Example-1: Use BERT Tokenizer and BERT pre-trained models\n",
    "\n",
    "### Load the pre-trained BERT model and its tokenizer.\n",
    "\n",
    "The model and tokenizer should be specifically designed for question-answering tasks:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzehpdEMP4WI",
    "outputId": "5770ee77-d641-4899-d667-72913d115986"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkPq_6noUuKg"
   },
   "source": [
    "### Tokenization:\n",
    "\n",
    "Tokenization is the process of converting raw text into a format suitable for input to the model. For BERT, this involves breaking text into tokens and mapping them to their corresponding IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Blended learning is an educational approach that combines traditional face-to-face classroom methods with online learning activities.\n",
    "This approach allows students to have greater control over the time, place, path, and pace of their learning. Blended learning \n",
    "environments often include interactive online resources, video lectures, and discussion forums, complemented by in-person sessions \n",
    "for hands-on activities and group discussions. Studies have shown that blended learning can improve student engagement and outcomes \n",
    "by catering to diverse learning styles and providing flexibility. However, its success depends on factors such as access to technology, \n",
    "the quality of digital content, and the support provided to students and teachers in using the platform effectively.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zFo69pk8VgHK"
   },
   "outputs": [],
   "source": [
    "question = \"What factors influence the success of blended learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RlGg2_vMUqtq"
   },
   "outputs": [],
   "source": [
    "# tokenize the input\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URsbRlX9V73D"
   },
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EluGzRfAVqPr"
   },
   "outputs": [],
   "source": [
    "output = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPMqbjiaV_dT"
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ls8EwwClV2pS",
    "outputId": "33654164-aa8d-4bb8-8dbd-9aa6db1c5418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-6.5302, -5.3346, -8.3935, -8.0089, -8.6484, -8.7349, -8.7004, -8.5287,\n",
       "         -8.9917, -9.6420, -6.5302, -5.3780, -7.3467, -7.8986, -7.6727, -5.9793,\n",
       "         -7.3046, -8.1219, -6.6036, -6.2408, -6.0657, -8.1827, -8.2430, -8.4577,\n",
       "         -7.3873, -6.8120, -7.4977, -8.1131, -4.8053, -6.9933, -6.2131, -6.5300,\n",
       "         -6.3940, -6.6710, -6.5075, -5.2907, -8.2768, -8.0668, -6.7163, -6.5301,\n",
       "         -8.3639, -7.7955, -5.3139, -8.3803, -6.4060, -8.4876, -7.0702, -8.4776,\n",
       "         -8.3069, -6.3323, -8.6986, -8.1035, -6.3115, -7.6198, -5.7240, -7.3479,\n",
       "         -6.4291, -6.6212, -6.9727, -4.5232, -5.0039, -6.8238, -8.0946, -5.6015,\n",
       "         -7.4493, -8.4153, -8.1296, -7.1262, -7.0449, -8.5884, -7.4438, -8.9439,\n",
       "         -8.6388, -6.8865, -8.7398, -8.1713, -7.9134, -8.6095, -6.3948, -8.8774,\n",
       "         -8.6048, -7.3579, -8.5953, -7.1161, -7.2918, -7.3383, -3.8796, -7.2120,\n",
       "         -6.1489, -7.4924, -4.1820, -6.5956, -6.0206, -5.0644, -5.4584, -6.7239,\n",
       "         -8.0780, -5.8118, -6.8107, -5.0089, -7.6431, -4.2349, -5.6446, -6.5395,\n",
       "         -7.7530, -5.4411, -4.6643, -6.8569, -3.8006, -3.5842,  0.7384,  0.0151,\n",
       "         -0.7901, -2.2720,  2.8167, -1.4945, -1.7062,  7.1183, -2.0596,  0.0646,\n",
       "         -3.9996, -0.8596, -0.2086, -5.2480, -3.4066, -4.0012, -5.5287, -5.0417,\n",
       "         -2.6643, -1.6338, -4.2398, -5.7947, -3.1463, -6.6635, -3.7349, -4.3868,\n",
       "         -4.1254, -6.1943, -4.0114, -4.1662, -4.6174, -6.5303]],\n",
       "       grad_fn=<CloneBackward0>), end_logits=tensor([[-1.9658, -5.2761, -7.8032, -7.7225, -7.8001, -7.6186, -7.6830, -7.6345,\n",
       "         -7.1618, -7.4591, -1.9657, -5.9054, -5.1592, -7.2117, -7.2501, -5.5539,\n",
       "         -6.0696, -7.3469, -7.0235, -6.6340, -6.6500, -7.6541, -7.2111, -7.5201,\n",
       "         -6.0488, -5.4984, -5.8354, -7.3346, -5.2065, -5.8061, -4.0410, -1.9660,\n",
       "         -7.4603, -6.9616, -7.7093, -5.8895, -7.5384, -7.5870, -7.4289, -6.3150,\n",
       "         -7.5499, -8.0039, -6.4696, -7.1967, -6.1495, -6.9383, -6.2590, -6.3281,\n",
       "         -7.5825, -4.1062, -7.3811, -7.3135, -4.1375, -4.1169, -7.3112, -6.3975,\n",
       "         -6.1471, -7.3292, -7.4168, -6.6197, -6.1666, -5.5093, -6.9730, -6.6455,\n",
       "         -5.6461, -6.2527, -7.3024, -6.4359, -3.4992, -4.9277, -7.3104, -6.4903,\n",
       "         -7.4727, -7.6582, -7.7738, -6.7927, -5.6474, -7.7227, -7.2888, -7.7448,\n",
       "         -7.2918, -5.8806, -7.8932, -7.3857, -4.6228, -4.0945, -5.9141, -7.0963,\n",
       "         -6.5834, -6.9994, -6.5121, -5.8716, -7.0113, -6.3403, -6.1827, -5.8914,\n",
       "         -7.8807, -4.2232, -7.4173, -7.2175, -7.5712, -6.0515, -6.0845, -5.0039,\n",
       "         -7.6353, -7.2241, -3.4353, -3.8514, -6.6311, -6.2860, -6.1347, -3.9328,\n",
       "         -4.1325, -4.4744, -2.9193, -5.1131, -4.0012, -1.8985, -4.2519,  0.5910,\n",
       "         -1.0905, -3.5113, -1.2359, -2.9345, -1.6969,  1.9658,  0.3665, -1.4564,\n",
       "         -2.3999,  1.2024,  0.4958, -2.6344,  1.2726, -3.3493,  5.1961, -1.0313,\n",
       "         -1.1000, -2.7767,  4.4510,  6.2032,  5.1059, -1.9662]],\n",
       "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kjUY5JlOWIb_"
   },
   "outputs": [],
   "source": [
    "answer_start_index = int(torch.argmax(output.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(torch.argmax(output.end_logits, axis=-1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iObMPGwpevYt"
   },
   "source": [
    "- **output.start_logits**: likely represents the output scores or logits generated by the model for the starting position of the answer span in the input passage.\n",
    "-  **output.end_logits** represents the output scores or logits generated by the model for the ending position of the answer span in the input passage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIUmAbBBiWCL"
   },
   "source": [
    "The returned response is unique IDs for the token. Using tokenizer to decode every token id into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "gnkODyZNRd0I",
    "outputId": "97a2902b-324c-4e67-a90c-450edccfaaa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'access to technology, the quality of digital content, and the support provided to students and teachers in using the platform effectively'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note: \n",
    "\n",
    "The Transformers library ensures compatibility between tokenizers and models. When selecting a model and tokenizer pair, make sure they are compatible and intended for the same architecture. For example, you should use a BERT tokenizer with a BERT model, a GPT-2 tokenizer with a GPT-2 model, and so on.\n",
    "\n",
    "The Hugging Face model hub provides a variety of pre-trained models and their associated tokenizers. You can find the specific model name in the documentation. For instance, if you're using BERT for sequence classification, you might use bert-base-uncased for both the tokenizer and the model.\n",
    "\n",
    "Remember to check the specific model's documentation for usage details related to inputs, outputs, and special features, as they can vary based on the model's architecture and intended task. The Transformers library documentation and Hugging Face's GitHub repository are excellent resources to explore more about different models, tokenizers, and their applications."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
